########################### RESULTS #########################
scipt: owl.py
base owl.py CV avg score: 0.922406, LB: 0.5704 #199 commit: 1ec7aae4e28326a4db9fe9329674a64e20b45a7c
depth=5(4) CV avg score: 0.916294, LB: 0.58710 worse
early_stopping_rounds=200(100) CV avg score: 0.922406 LB 0.57805
n_components1=30(20) CV: 0.92417 LB 0.57633 new best #197 commit: 4b996d579c6a083c1f74776eaca4169ecad17350
n_components1=50(20) CV: 0.929749 LB 0.60998
n_components1=40(20) CV: 0.927191 no submitted
n_components1=25(20) CV: 0.921756 LB 0.58630
pi2 ngram_range(1,2) CV: 0.929666 LB 0.63893
pi2 ngram_range(1,10) CV: 0.92007 LB: 0.59959 
n_iter=50(25) in pipeline CV: 0.925136 LB: 0.58522
n_iter=50(25) FOLD=4 in pipeline CV: 0.886404165448 LB: 0.60805
n_components2=25(50) CV: 0.934051
n_components2=75(50) CV: 0.920083 LB 0.56993 new best #118
n_components2=100(50) CV: 0.913578 LB 0.61207 worse
n_components2=75(50) stop_words='english' CV: 


* max_features
* transformer_weights, see: /Users/lchernin/misc/hd/rf/xg.py

* which of the four functions in pipeline is most important
standard CV: 0.970832
pi1 CV: 1.18485
pi2 CV: 1.62459
pi3 CV: 0.989647

transformer_weighted CV: 0.920078 LB: 0.56993 tied with best
maybe it does this automatically?



why CV is not predictive??? Recent entry had best local score and worst LB??
test_size=0.25(0.18) n_components2=100(50) CV: 0.91676 LB: 0.64328
test_size=0.16(0.18) n_components2=75(50) CV: 0.909985 LB: 0.59464


decomposition.TruncatedSV  => PCA?
change components for TFIDF  
review TFIDF?

standard_cv = 0.970832 * 0.9 CV: 0.920382 LB: 0.56718 new best #114 commit f916a2925fe6572f594e670d2cfb414be0f8effd
standard_cv = 0.970832 * 0.8 CV: 0.920094 LB: 0.56993 
pi3_cv = 0.989647 * 0.9 CV: 0.920078  LB: 0.56993
TFIDF/stopwords=english crash
TFIDF/max_features=2000 CV: 0.929658 LB: 0.68045
TFIDF/max_features=10000 CV: 0.923816 LB: 0.63629
max_depth=5(4)  CV: 0.910077 LB: 0.56646 new best #113 
max_depth=6(4)  CV: 0.9043 LB: 0.55771 new best #86 commit:  360b9e1c178a28aff3c220a855d3eb6a888536d5
max_depth=7(4)  CV: 0.904765  LB: 0.57348 


features count these words: pathogenic, benign, inhibitor and their ratios CV: 0.902064 LB: 0.56519 worse!

stem text: SnowballC
CV 0.908614  LB: 0.59060

TODO: 
remove slow words from text: mutation, cancer, tumor,fig, figure, et, al, table, data, analysis, analyze, study, method, result, conclusion, author, find, found, show, perform, demonstrate, evaluate, discuss
==> Memory errors

stopwords=english on AWS CV: 0.905511  LB: 0.62609
smaller eta =0.015(0.0333) CV: 0.906148  LB: 0.58593
max_depth=8(4)

####################### stage 2 ######################
owl.py, max_depth=8(6) CV: 0.909329  LB: 0.96744 #5 rank
owl.py, max_depth=7(6) CV: 0.904749 LB: 0.97559 worse
owl2.py with test from stage 1, CV: 0.866846 LB: 0.40674 new best #12 committed
owl2.py same as prev, but max_depth=7(6) CV: 0.86259 LB: 0.36370 #3 committed  BEST CV SO FAR, so include it!
owl2.py same as prev, but max_depth=8(6) CV: 0.865962 LB: 0.34411 new best
owl2.py same as prev, but max_depth=10(6) CV: 0.8699 LB: 0.32604 new best
owl2.py same as prev, but max_depth=12(6) CV: 0.874938 LB: 0.32161 new best
owl2.py same as prev, but max_depth=15(6) CV: 0.882401 LB: 0.31877 new best #18
owl2.py same as prev, but max_depth=20(6) CV: 0.881372 LB: 0.31393 new best #18
owl2.py same as prev, but early_stopping_rounds=200(100) same as above.
owl2.py same as prev,early_stopping_rounds=100, max_depth=30(6), CV: 0.883679
ren.py  stage1 solution as stage2 submission, LB: 0.14012


adjust weights?
stopwords?
try new features here: https://www.kaggle.com/danofer/genetic-variants-to-protein-features/output

# take sub_ren.csv and replace any fillna values with high confidence predictions from owl2.py sub.csv
combined.py replacement_threshold=0.8, replaced 64 values, uses max_depth=30(6), CV: 0.883679, LB: 0.16396
combined.py replacement_threshold=0.94, replaced 11 values, uses max_depth=30(6), CV: 0.883679, LB: 0.15188

